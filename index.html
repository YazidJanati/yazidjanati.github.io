<html>
<head><meta charset="utf-8"><meta name="keywords" content="Janati, Yazid">
	<link href="style.css" rel="stylesheet" type="text/css" />
	<title>Yazid Janati El Idrissi</title>
</head>
<body>
<div id="title"></div>

<div class="main" style="padding-right: 2px; 
                  margin-left: 200px; 
                  margin-right: 200px;
                  padding-left: 2px;"><!-- <div style="float: left; width: 100%"> -->

<div style="width:100%">
<p><span class="boldbig">Yazid Janati El Idrissi</span></p>
</div>
<a href="https://scholar.google.com/citations?user=JGor6XwAAAAJ&hl=en"></br>Google Scholar</a>  
<a href="https://github.com/yazidjanati"> / Github</a>
<a href="mailto: janati.yazid@gmail.com"> / Email</a>  


<p></br>
    I am a third year PhD candidate in statistics at Télécom SudParis - Institut Polytechnique de Paris, advised by <a href="https://sylvainlc.github.io">Sylvain Le Corff</a> (LPSM, Sorbonne Université) and <a href = "http://www-public.imtbs-tsp.eu/~petetin/">Yohan Petetin</a> (CITI, Télécom SudParis).
</br></br>
    I am interested in building new algorithms related to Monte Carlo methods and studying their theoretical properties. I am particularly interested in the interplay between MC and deep learning methods. At the moment I am heavily into <em>importance sampling</em> and trying to understand how to build efficient proposals through the minimization of divergence measures.

</br>
</br>
<hr> 
<p><span class="boldbig">Publications</span></p>

<p><a href = "https://arxiv.org/abs/2301.00900"><b>State and parameter learning with PaRISian Particle Gibbs</b></a>
</br> 
G. Cardoso, YJEL, S. Le Corff, E. Moulines and J. Olsson. 
</br><em>Under review.</em>
</br>

<p><a href = "https://arxiv.org/pdf/2204.01401.pdf"><b>Variance estimation for Sequential Monte Carlo Algorithms: a backward sampling approach
</b></a>
</br> 
YJEL, S. Le Corff and Y. Petetin. 
</br><em>Accepted for publication in Bernoulli.</em>
</br>

<p><a href = "https://proceedings.neurips.cc/paper/2021/file/8dd291cbea8f231982db0fb1716dfc55-Paper.pdf"><b>NEO: Non Equilibrium Sampling on the Orbit of a Deterministic Transform</b></a>
</br> 
A. Thin, YJEL, S. Le Corff, C. Ollion, A. Doucet, A. Durmus, E. Moulines and C. Robert.
</br><em>Advances in Neural Information Processing Systems (NeurIPS) 34 (2021): 17060-17071.</em>
</br>

<p><a href = "https://ieeexplore.ieee.org/document/9540246/"><b>Structured variational Bayesian inference for Gaussian state-space models with regime switching.</b></a>
</br> 
Y. Petetin, YJEL and F. Desbouvries.
</br><em>IEEE Signal Processing Letters 28 (2021): 1953-1957.</em>
</br>

</br>
<p><span class="boldbig">Talks and posters</span></p>
</br>
<b>An iterative scheme for backward Kullback-Leibler minimization</b>
<ul>
<li>Workshop "On Future Trends and Opportunities for Monte Carlo methods", University of Warsaw, 12/2022.</li>
<li>PhD students seminar, LPSM, Sorbonne Université, 11/2022.</li>
<li>Rencontres statistiques du CEREMADE, Université Paris Dauphine, 11/2022.</li>
<li>MIA seminar, Agro ParisTech, 09/2022.</li>
<li>Mathematics in Machine Learning summer school, UM6P University, Ben Guerir, 07/2022.</li>
</ul>
</br>
<b>Variance estimation for Sequential Monte Carlo Algorithms</b>
<ul>
<li>5th SMC workshop (poster), UC3M, Madrid, 05/2022.</li>
<li>PhD students seminar, Télécom Paris, 04/2022.</li>
</ul>
</br>
<b>Non Equilibrium Sampling on the Orbit of a Deterministic Transform</b>
<ul>
    <li>NeuRIPS in Paris (poster), SCAI Sorbonne, 11/2021.</li>
    </ul>
</p>
</div>
</body>
</html>